{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6178bc7-6e83-49ec-b7f4-61da5dd6d121",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Logistic Regression\n",
    "\n",
    "### Objectives\n",
    "* Using scikit Logistic Regression to Classify \n",
    "* Understand Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681fd0a0-53d8-4886-bd85-c8e271fb6f27",
   "metadata": {},
   "source": [
    "* In this lab, we will learn Logistic Regression, and then, we'll create a model for a telecommunication company, to predict when its customers will leave for a competitor, so that they can take some action to retain the customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbebd057-e469-47d6-9020-c06682ef51b9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## What is the difference between Linear and Logistic Regression?\n",
    "\n",
    "* While **Linear Regression** is suited for estimating continuous values (e.g. estimating house price), it is not the best tool for predicting the class of an observed data point, **y**. In order to estimate the class of a data point, we need some sort of guidance on what would be the most probable class for that data point. For this, we use **Logistic Regression**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93c2765-5047-44c0-8337-a8d0272f0a03",
   "metadata": {},
   "source": [
    "## About the dataset\n",
    "We will use a telecommunications dataset for predicting customer churn. This is a historical customer dataset where each row represents one customer. The data is relatively easy to understand, and you may uncover insights you can use immediately. Typically it is less expensive to keep customers than acquire new ones, so the focus of this analysis is to predict the customers who will stay with the company.\n",
    "This data set provides information to help you predict what behavior will help you to retain customers. We can analyze all relevant customer data and develop focused customer retention programs.\n",
    "\n",
    "The dataset includes information about:\n",
    "\n",
    "* Customers who left within the last month – the column is called Churn\n",
    "* Services that each customer has signed up for – phone, multiple lines, internet, online security, online backup, device protection, tech support, and streaming TV and movies\n",
    "* Customer account information – how long they had been a customer, contract, payment method, paperless billing, monthly charges, and total charges\n",
    "* Demographic info about customers – gender, age range, and if they have partners and dependents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "792ef51d-584a-4d57-baac-d16eeabc906b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    142\n",
       "1     58\n",
       "Name: churn, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# data file\n",
    "df = pd.read_csv('C:\\\\Users\\\\LENOVO\\\\Downloads\\\\ChurnData.csv')\n",
    "\n",
    "df['churn'] = df['churn'].astype('int')\n",
    "# let's see how many will churn (leave the company) and \n",
    "df['churn'].value_counts()\n",
    "\n",
    "# Data vectors\n",
    "X = df.drop(columns = ['churn']) # Data matrix\n",
    "y = df['churn'].values   # Response Vector (target)\n",
    "\n",
    "#Preproccessing vectors\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "# Test-Train Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(X,y, test_size = 0.2, random_state = 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575d2c98-c51e-43f4-939d-dce24d3ff839",
   "metadata": {},
   "source": [
    "### Training Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5713e41d-9ba1-41d8-93ec-da87e5c46f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "LR = LogisticRegression(C = 0.01, solver = 'liblinear').fit(train_x, train_y)\n",
    "\n",
    "# Testing\n",
    "y_hat = LR.predict(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f5aca6-afa0-4969-b0fc-960387c0a672",
   "metadata": {},
   "source": [
    "* **predict_proba** returns estimates for all classes, ordered by the label of classes. So, the first column is the probability of class 0, P(Y=0|X), and second column is probability of class 1, P(Y=1|X):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de690069-f178-4daa-a426-ea4f64b2fd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_prob = LR.predict_proba(test_X)\n",
    "yhat_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b5260a-997e-4107-a130-588b5b781d35",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81860a18-6661-4b0b-9e59-263de330ac5c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Putting the code together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4153d7c0-74ec-4110-b9b3-cf46943c8011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.60722328, 0.39277672],\n",
       "       [0.61809654, 0.38190346],\n",
       "       [0.58411229, 0.41588771],\n",
       "       [0.65417657, 0.34582343],\n",
       "       [0.57846128, 0.42153872],\n",
       "       [0.60571723, 0.39428277],\n",
       "       [0.49465243, 0.50534757],\n",
       "       [0.63096405, 0.36903595],\n",
       "       [0.37261192, 0.62738808],\n",
       "       [0.57501555, 0.42498445],\n",
       "       [0.43796261, 0.56203739],\n",
       "       [0.56949003, 0.43050997],\n",
       "       [0.52659009, 0.47340991],\n",
       "       [0.38212909, 0.61787091],\n",
       "       [0.68571532, 0.31428468],\n",
       "       [0.52974013, 0.47025987],\n",
       "       [0.49534501, 0.50465499],\n",
       "       [0.54486783, 0.45513217],\n",
       "       [0.42671406, 0.57328594],\n",
       "       [0.58188784, 0.41811216],\n",
       "       [0.50068924, 0.49931076],\n",
       "       [0.41069809, 0.58930191],\n",
       "       [0.80418638, 0.19581362],\n",
       "       [0.34302289, 0.65697711],\n",
       "       [0.43713534, 0.56286466],\n",
       "       [0.75147663, 0.24852337],\n",
       "       [0.39496994, 0.60503006],\n",
       "       [0.42173992, 0.57826008],\n",
       "       [0.53615371, 0.46384629],\n",
       "       [0.82329995, 0.17670005],\n",
       "       [0.74876986, 0.25123014],\n",
       "       [0.60601763, 0.39398237],\n",
       "       [0.31608844, 0.68391156],\n",
       "       [0.72967456, 0.27032544],\n",
       "       [0.70767479, 0.29232521],\n",
       "       [0.60199123, 0.39800877],\n",
       "       [0.36515497, 0.63484503],\n",
       "       [0.60399177, 0.39600823],\n",
       "       [0.84359251, 0.15640749],\n",
       "       [0.37455692, 0.62544308]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# data file\n",
    "df = pd.read_csv('C:\\\\Users\\\\LENOVO\\\\Downloads\\\\ChurnData.csv')\n",
    "\n",
    "df['churn'] = df['churn'].astype('int')\n",
    "# let's see how many will churn (leave the company) and \n",
    "df['churn'].value_counts()\n",
    "\n",
    "# Data vectors\n",
    "X = df.drop(columns = ['churn']) # Data matrix\n",
    "y = df['churn'].values   # Response Vector (target)\n",
    "\n",
    "#Preproccessing vectors\n",
    "from sklearn import preprocessing\n",
    "X = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "# Test-Train Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X, test_X, train_y, test_y = train_test_split(X,y, test_size = 0.2, random_state = 4)\n",
    "\n",
    "#Train the model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "LR = LogisticRegression(C = 0.01, solver = 'liblinear').fit(train_X, train_y)\n",
    "\n",
    "# Testing\n",
    "y_hat = LR.predict(test_X)\n",
    "\n",
    "yhat_prob = LR.predict_proba(test_X)\n",
    "yhat_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfe262b-eb1b-4fe7-bf88-760f165c40e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
